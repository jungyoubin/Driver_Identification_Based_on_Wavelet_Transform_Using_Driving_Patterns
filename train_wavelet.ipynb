{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de005fba-28bb-431a-97c3-716dddab9d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv('./11_CAN_window60.csv', encoding='cp949')\n",
    "df = df.sample(frac=1, random_state=7777).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac9a397c-f4cc-47d4-b7b1-ab163fac6c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_col = ['RearHeatPower266', 'DI_accelPedalPos', 'SmoothBattCurrent132', 'VCFRONT_chillerExvFlowm3', 'BMS_maxDischargePower', 'DI_regenLight', 'DI_regenLight', 'DIR_torqueActual', 'DIR_torqueCommand', 'DIR_torqueActual', 'SystemHeatPowerMax268', 'SystemHeatPower268', 'VCFRONT_pumpBatteryRPMActualm0', 'BattVoltage132', 'SteeringSpeed129', 'SteeringAngle129', 'DI_vehicleSpeed', 'label', 'drive_count', 'course'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6835d3b3-d91e-4b20-ab16-9f0517f8da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 몇 개 제외\n",
    "df = df[[col for col in df.columns if any(substring in col for substring in use_col)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7473e24e-a5ef-466f-ae19-8c631b86e24f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df[df['course'] != 0]\n",
    "df_valid = df[df['course'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29106f7b-4da3-48d1-a45f-68f4b420ce95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_valid['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f89a69b8-39f5-4eac-8ffe-55ad316f0858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = df_train.drop(['course', 'drive_count'], axis=1)\n",
    "valid_data = df_valid.drop(['course', 'drive_count'], axis=1)\n",
    "\n",
    "train_data.reset_index(inplace=True, drop=True)\n",
    "valid_data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "X_train = train_data.drop('label', axis=1)\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_valid = valid_data.drop('label', axis=1)\n",
    "y_valid = valid_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87050691-a569-4100-b3d4-b3000e05ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 drop\n",
    "X_train = X_train.dropna()\n",
    "y_train = y_train[X_train.index]\n",
    "\n",
    "X_valid = X_valid.dropna()\n",
    "y_valid = y_valid[X_valid.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72aeac69-e5c5-4d27-98df-ec793573235d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeafe04-8954-4522-a8b0-793a0d167cdb",
   "metadata": {},
   "source": [
    "### SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "161a300b-8384-42a0-8212-d55ca0b48f28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # SVM 모델 생성 및 학습\n",
    "# svm_model = SVC(C=1.0, kernel='poly', probability=True, random_state=42)\n",
    "# svm_model.fit(X_train, y_train)\n",
    "\n",
    "# # # 예측\n",
    "# # y_pred = svm_model.predict(X_valid)\n",
    "\n",
    "# # # 정확도 평가\n",
    "# # accuracy = accuracy_score(y_valid, y_pred)\n",
    "# # print(\"SVM 정확도:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c20e03d9-bf79-4f62-bf7f-43b9d54f047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 예측 확률 계산\n",
    "# y_pred_prob = svm_model.predict_proba(X_valid)\n",
    "\n",
    "# # 레이블에 따라 확률을 그룹화\n",
    "# grouped_prob = {label: [] for label in np.unique(y_train)}\n",
    "# for prob, label in zip(y_pred_prob, y_valid):\n",
    "#     grouped_prob[label].append(prob)\n",
    "\n",
    "# # 보팅 방식에 따른 정확도 계산\n",
    "# def calculate_accuracy(grouped_prob, vote_count):\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for label, probs in grouped_prob.items():\n",
    "#         for i in range(0, len(probs), vote_count):\n",
    "#             avg_prob = np.mean(probs[i:i + vote_count], axis=0)\n",
    "#             predicted_label = np.argmax(avg_prob)\n",
    "#             correct += predicted_label == label\n",
    "#             total += 1\n",
    "#     return correct / total if total > 0 else 0\n",
    "\n",
    "# accuracy_1_voting = calculate_accuracy(grouped_prob, 1)\n",
    "# accuracy_3_voting = calculate_accuracy(grouped_prob, 3)\n",
    "# accuracy_10_voting = calculate_accuracy(grouped_prob, 10)\n",
    "# accuracy_all_voting = calculate_accuracy(grouped_prob, len(y_valid))\n",
    "\n",
    "# # print(\"1 Voting 정확도:\", accuracy_1_voting)\n",
    "# # print(\"3 Voting 정확도:\", accuracy_3_voting)\n",
    "# # print(\"10 Voting 정확도:\", accuracy_10_voting)\n",
    "# # print(\"All Voting 정확도:\", accuracy_all_voting)\n",
    "# print(\"1 Voting 정확도:\", round(accuracy_1_voting, 4))\n",
    "# print(\"3 Voting 정확도:\", round(accuracy_3_voting, 4))\n",
    "# print(\"10 Voting 정확도:\", round(accuracy_10_voting, 4))\n",
    "# print(\"All Voting 정확도:\", round(accuracy_all_voting, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd3ae11-7013-4fd7-8438-d3447aaac2e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### RF (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cce52c6c-1d2e-4a19-803f-12d947b947a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Random Forest 모델 생성 및 학습\n",
    "# rf_model = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n",
    "# rf_model.fit(X_train, y_train)\n",
    "\n",
    "# # # 예측\n",
    "# # y_pred_rf = rf_model.predict(X_valid)\n",
    "\n",
    "# # # 정확도 평가\n",
    "# # accuracy_rf = accuracy_score(y_valid, y_pred_rf)\n",
    "# # print(\"Random Forest 정확도:\", accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee9775d1-dc03-4c08-a0bb-426bd36bb4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 예측 확률 계산\n",
    "# y_pred_prob = rf_model.predict_proba(X_valid)\n",
    "\n",
    "# # 레이블에 따라 확률을 그룹화\n",
    "# grouped_prob = {label: [] for label in np.unique(y_train)}\n",
    "# for prob, label in zip(y_pred_prob, y_valid):\n",
    "#     grouped_prob[label].append(prob)\n",
    "\n",
    "# # 보팅 방식에 따른 정확도 계산\n",
    "# def calculate_accuracy(grouped_prob, vote_count):\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for label, probs in grouped_prob.items():\n",
    "#         for i in range(0, len(probs), vote_count):\n",
    "#             avg_prob = np.mean(probs[i:i + vote_count], axis=0)\n",
    "#             predicted_label = np.argmax(avg_prob)\n",
    "#             correct += predicted_label == label\n",
    "#             total += 1\n",
    "#     return correct / total if total > 0 else 0\n",
    "\n",
    "# accuracy_1_voting = calculate_accuracy(grouped_prob, 1)\n",
    "# accuracy_3_voting = calculate_accuracy(grouped_prob, 3)\n",
    "# accuracy_10_voting = calculate_accuracy(grouped_prob, 10)\n",
    "# accuracy_all_voting = calculate_accuracy(grouped_prob, len(y_valid))\n",
    "\n",
    "# # print(\"1 Voting 정확도:\", accuracy_1_voting)\n",
    "# # print(\"3 Voting 정확도:\", accuracy_3_voting)\n",
    "# # print(\"10 Voting 정확도:\", accuracy_10_voting)\n",
    "# # print(\"All Voting 정확도:\", accuracy_all_voting)\n",
    "# print(\"1 Voting 정확도:\", round(accuracy_1_voting, 4))\n",
    "# print(\"3 Voting 정확도:\", round(accuracy_3_voting, 4))\n",
    "# print(\"10 Voting 정확도:\", round(accuracy_10_voting, 4))\n",
    "# print(\"All Voting 정확도:\", round(accuracy_all_voting, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ff8846-8f9f-4d75-9425-ca7774da6d47",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afef1b76-3f11-487c-932e-7a695d7693ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device='cuda', early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost 모델 GPU로 학습\n",
    "import xgboost as xgb\n",
    "\n",
    "# xgb_model = xgb.XGBClassifier(max_depth=6, learning_rate=0.1, n_estimators=1000, random_state=42, tree_method='gpu_hist')  # GPU 사용 설정\n",
    "xgb_model = xgb.XGBClassifier(max_depth=6, learning_rate=0.1, n_estimators=1000, random_state=42, device = 'cuda')  # GPU 사용 설정\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_xgb = xgb_model.predict(X_valid)\n",
    "\n",
    "# # 정확도 평가\n",
    "# accuracy_xgb = accuracy_score(y_valid, y_pred_xgb)\n",
    "# print(\"XGBoost 정확도:\", accuracy_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86296067-11d5-4716-93f0-b1c84cbd22b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MMC_JYB\\anaconda3\\envs\\yb\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\MMC_JYB\\anaconda3\\envs\\yb\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting 1: 정확도 = 26.3, TOP-3 정확도 = 56.9, MAP = 18.2, F1 스코어 = 25.1\n",
      "Voting 3: 정확도 = 33.0, TOP-3 정확도 = 63.0, MAP = 27.2, F1 스코어 = 31.0\n",
      "Voting 10: 정확도 = 42.4, TOP-3 정확도 = 71.5, MAP = 37.5, F1 스코어 = 38.2\n",
      "Voting all: 정확도 = 40.0, TOP-3 정확도 = 70.0, MAP = 56.0, F1 스코어 = 36.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MMC_JYB\\anaconda3\\envs\\yb\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\MMC_JYB\\anaconda3\\envs\\yb\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\MMC_JYB\\anaconda3\\envs\\yb\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# 예측 확률 계산\n",
    "y_pred_prob = xgb_model.predict_proba(X_valid)\n",
    "\n",
    "# 레이블에 따라 확률을 그룹화\n",
    "grouped_prob = {label: [] for label in np.unique(y_valid)}\n",
    "for prob, label in zip(y_pred_prob, y_valid):\n",
    "    grouped_prob[label].append(prob)\n",
    "\n",
    "# TOP-3 정확도 계산 함수\n",
    "def top_3_accuracy(probs, labels):\n",
    "    correct = 0\n",
    "    for prob, label in zip(probs, labels):\n",
    "        top_3_labels = np.argsort(prob)[-3:]\n",
    "        correct += label in top_3_labels\n",
    "    return correct / len(labels)\n",
    "\n",
    "# 다중 클래스 MAP 계산 함수\n",
    "def mean_average_precision_multiclass(probs, y_true, n_classes):\n",
    "    y_true_bin = label_binarize(y_true, classes=range(n_classes))\n",
    "    average_precisions = []\n",
    "    for i in range(n_classes):\n",
    "        precision, recall, _ = precision_recall_curve(y_true_bin[:, i], probs[:, i])\n",
    "        ap = np.trapz(recall, precision)\n",
    "        average_precisions.append(ap)\n",
    "    return np.mean(average_precisions)\n",
    "\n",
    "# F1 스코어 계산 함수\n",
    "def f1_score(y_true, y_pred):\n",
    "    _, _, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "    return f1\n",
    "\n",
    "# 예측을 집계하고 평가 지표를 계산하는 함수\n",
    "def evaluate_performance(grouped_prob, vote_count, n_classes):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_scores = []\n",
    "    for label, probs in grouped_prob.items():\n",
    "        for i in range(0, len(probs), vote_count):\n",
    "            avg_prob = np.mean(probs[i:i + vote_count], axis=0)\n",
    "            predicted_label = np.argmax(avg_prob)\n",
    "            y_true.append(label)\n",
    "            y_pred.append(predicted_label)\n",
    "            y_scores.append(avg_prob)\n",
    "\n",
    "    acc = np.mean(np.array(y_pred) == np.array(y_true))\n",
    "    top_3_acc = top_3_accuracy(np.array(y_scores), np.array(y_true))\n",
    "    map_score = mean_average_precision_multiclass(np.array(y_scores), np.array(y_true), n_classes)\n",
    "    f1 = f1_score(np.array(y_true), np.array(y_pred))\n",
    "\n",
    "    return acc, top_3_acc, map_score, f1\n",
    "\n",
    "# all voting\n",
    "def evaluate_performance_all(grouped_prob, n_classes):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_scores = []\n",
    "    for idx in range(len(grouped_prob)):\n",
    "        # 각 드라이버의 예측 확률값\n",
    "        driver = grouped_prob[idx]\n",
    "        # 클래스별 평균 확률값 계산\n",
    "        avg_prob = np.mean(np.array(driver), axis=0)\n",
    "        # 가장 높은 확률을 가진 클래스 선택\n",
    "        predicted_label = np.argmax(avg_prob)\n",
    "        \n",
    "        y_true.append(idx)\n",
    "        y_pred.append(predicted_label)\n",
    "        y_scores.append(avg_prob)\n",
    "        \n",
    "    acc = np.mean(np.array(y_pred) == np.array(y_true))\n",
    "    top_3_acc = top_3_accuracy(np.array(y_scores), np.array(y_true))\n",
    "    map_score = mean_average_precision_multiclass(np.array(y_scores), np.array(y_true), n_classes)\n",
    "    f1 = f1_score(np.array(y_true), np.array(y_pred))\n",
    "    \n",
    "    return acc, top_3_acc, map_score, f1\n",
    "\n",
    "# 각 보팅 방식에 대한 평가 지표 계산\n",
    "n_classes = len(np.unique(y_valid))\n",
    "for vote_count in [1, 3, 10]:\n",
    "    acc, top_3_acc, map_score, f1 = evaluate_performance(grouped_prob, vote_count, n_classes)\n",
    "    print(f\"Voting {vote_count}: 정확도 = {np.round(acc*100, 1)}, TOP-3 정확도 = {np.round(top_3_acc*100, 1)}, MAP = {np.round(map_score*100, 1)}, F1 스코어 = {np.round(f1*100, 1)}\")\n",
    "\n",
    "# all voting\n",
    "acc, top_3_acc, map_score, f1 = evaluate_performance_all(grouped_prob, n_classes)\n",
    "print(f\"Voting all: 정확도 = {np.round(acc*100, 1)}, TOP-3 정확도 = {np.round(top_3_acc*100, 1)}, MAP = {np.round(map_score*100, 1)}, F1 스코어 = {np.round(f1*100, 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cee6356-c42f-4cee-aa2c-ec49f8d2b5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting 1: 정확도 = 38.2, TOP-3 정확도 = 67.6, MAP = 36.8, F1 스코어 = 36.0\n",
      "Voting 3: 정확도 = 49.3, TOP-3 정확도 = 73.9, MAP = 48.8, F1 스코어 = 45.6\n",
      "Voting 10: 정확도 = 60.0, TOP-3 정확도 = 80.3, MAP = 61.6, F1 스코어 = 54.5\n",
      "Voting all: 정확도 = 72.7, TOP-3 정확도 = 81.8, MAP = 87.1, F1 스코어 = 63.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MMC_JYB\\anaconda3\\envs\\yb\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import precision_recall_fscore_support, precision_recall_curve\n",
    "# from sklearn.preprocessing import label_binarize\n",
    "# from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "# # 예측 확률 계산\n",
    "# y_pred_prob = xgb_model.predict_proba(X_valid)\n",
    "\n",
    "\n",
    "# # 레이블에 따라 확률을 그룹화\n",
    "# grouped_prob = {label: [] for label in np.unique(y_train)}\n",
    "# for prob, label in zip(y_pred_prob, y_valid):\n",
    "#     grouped_prob[label].append(prob)\n",
    "\n",
    "# # TOP-3 정확도 계산 함수\n",
    "# def top_3_accuracy(probs, labels):\n",
    "#     correct = 0\n",
    "#     for prob, label in zip(probs, labels):\n",
    "#         top_3_labels = np.argsort(prob)[-3:]\n",
    "#         correct += label in top_3_labels\n",
    "#     return correct / len(labels)\n",
    "\n",
    "# # F1 스코어 계산 함수\n",
    "# def f1_score(y_true, y_pred):\n",
    "#     _, _, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "#     return f1\n",
    "\n",
    "# # mAP 점수 계산 함수\n",
    "# def calculate_map_score(y_true_bin, y_scores):\n",
    "#     map_score = 0\n",
    "#     for i in range(n_classes):\n",
    "#         ap = average_precision_score(y_true_bin[:, i], np.array(y_scores)[:, i])\n",
    "#         map_score += ap\n",
    "#     return map_score / n_classes\n",
    "\n",
    "# # 예측을 집계하고 평가 지표를 계산하는 함수\n",
    "# def evaluate_performance(grouped_prob, vote_count, n_classes):\n",
    "#     y_true = []\n",
    "#     y_pred = []\n",
    "#     y_scores = []\n",
    "#     for label, probs in grouped_prob.items():\n",
    "#         for i in range(0, len(probs), vote_count):\n",
    "#             avg_prob = np.mean(probs[i:i + vote_count], axis=0)\n",
    "#             predicted_label = np.argmax(avg_prob)\n",
    "#             y_true.append(label)\n",
    "#             y_pred.append(predicted_label)\n",
    "#             y_scores.append(avg_prob)\n",
    "\n",
    "#     acc = np.mean(np.array(y_pred) == np.array(y_true))\n",
    "#     y_true_bin = label_binarize(y_true, classes=np.arange(n_classes))\n",
    "#     map_score = calculate_map_score(np.array(y_true_bin), np.array(y_scores))\n",
    "#     top_3_acc = top_3_accuracy(np.array(y_scores), np.array(y_true))\n",
    "#     f1 = f1_score(np.array(y_true), np.array(y_pred))\n",
    "\n",
    "#     return acc, top_3_acc, f1, map_score\n",
    "\n",
    "# # all voting\n",
    "# def evaluate_performance_all(grouped_prob, n_classes):\n",
    "#     y_true = []\n",
    "#     y_pred = []\n",
    "#     y_scores = []\n",
    "#     for idx in range(len(grouped_prob)):\n",
    "#         # 각 드라이버의 예측 확률값\n",
    "#         driver = grouped_prob[idx]\n",
    "#         # 클래스별 평균 확률값 계산\n",
    "#         avg_prob = np.mean(np.array(driver), axis=0)\n",
    "#         # 가장 높은 확률을 가진 클래스 선택\n",
    "#         predicted_label = np.argmax(avg_prob)\n",
    "        \n",
    "#         y_true.append(idx)\n",
    "#         y_pred.append(predicted_label)\n",
    "#         y_scores.append(avg_prob)\n",
    "        \n",
    "#     acc = np.mean(np.array(y_pred) == np.array(y_true))\n",
    "#     top_3_acc = top_3_accuracy(np.array(y_scores), np.array(y_true))\n",
    "#     # print(y_scores)\n",
    "#     # print(y_true)\n",
    "#     f1 = f1_score(np.array(y_true), np.array(y_pred))\n",
    "#     y_true_bin = label_binarize(y_true, classes=np.arange(n_classes))\n",
    "#     map_score = calculate_map_score(np.array(y_true_bin), np.array(y_scores))\n",
    "#     return acc, top_3_acc, f1, map_score\n",
    "\n",
    "# # 각 보팅 방식에 대한 평가 지표 계산\n",
    "# n_classes = len(np.unique(y_train))\n",
    "# for vote_count in [1, 3, 10]:\n",
    "#     acc, top_3_acc, f1, map_score = evaluate_performance(grouped_prob, vote_count, n_classes)\n",
    "#     print(f\"Voting {vote_count}: 정확도 = {np.round(acc*100, 1)}, TOP-3 정확도 = {np.round(top_3_acc*100, 1)}, MAP = {np.round(map_score*100, 1)}, F1 스코어 = {np.round(f1*100, 1)}\")\n",
    "\n",
    "# # all voting\n",
    "# acc, top_3_acc, f1, map_score = evaluate_performance_all(grouped_prob, n_classes)\n",
    "# print(f\"Voting all: 정확도 = {np.round(acc*100, 1)}, TOP-3 정확도 = {np.round(top_3_acc*100, 1)}, MAP = {np.round(map_score*100, 1)}, F1 스코어 = {np.round(f1*100, 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3bb6bd-b626-4816-9e23-6c41b7559bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
